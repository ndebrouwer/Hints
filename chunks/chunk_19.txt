        __proto__: null,
        newAccumulator: newAccumulator,
        exportChallenge: exportChallenge,
        importResponse: importResponse,
        verify: verify,
        challengeContribute: challengeContribute,
        beacon: beacon$1,
        contribute: contribute,
        preparePhase2: preparePhase2,
        truncate: truncate,
        convert: convert,
        exportJson: exportJson
    });

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */

    function r1csPrint(r1cs, syms, logger) {
        for (let i=0; i<r1cs.constraints.length; i++) {
            printCostraint(r1cs.constraints[i]);
        }
        function printCostraint(c) {
            const lc2str = (lc) => {
                let S = "";
                const keys = Object.keys(lc);
                keys.forEach( (k) => {
                    let name = syms.varIdx2Name[k];
                    if (name == "one") name = "";

                    let vs = r1cs.curve.Fr.toString(lc[k]);
                    if (vs == "1") vs = "";  // Do not show ones
                    if (vs == "-1") vs = "-";  // Do not show ones
                    if ((S!="")&&(vs[0]!="-")) vs = "+"+vs;
                    if (S!="") vs = " "+vs;
                    S= S + vs   + name;
                });
                return S;
            };
            const S = `[ ${lc2str(c[0])} ] * [ ${lc2str(c[1])} ] - [ ${lc2str(c[2])} ] = 0`;
            if (logger) logger.info(S);
        }

    }

    const SUBARRAY_SIZE$1 = 0x40000;

    const BigArrayHandler$1 = {
        get: function(obj, prop) {
            if (!isNaN(prop)) {
                return obj.getElement(prop);
            } else return obj[prop];
        },
        set: function(obj, prop, value) {
            if (!isNaN(prop)) {
                return obj.setElement(prop, value);
            } else {
                obj[prop] = value;
                return true;
            }
        }
    };

    class _BigArray$1 {
        constructor (initSize) {
            this.length = initSize || 0;
            this.arr = new Array(SUBARRAY_SIZE$1);

            for (let i=0; i<initSize; i+=SUBARRAY_SIZE$1) {
                this.arr[i/SUBARRAY_SIZE$1] = new Array(Math.min(SUBARRAY_SIZE$1, initSize - i));
            }
            return this;
        }
        push () {
            for (let i=0; i<arguments.length; i++) {
                this.setElement (this.length, arguments[i]);
            }
        }

        slice (f, t) {
            const arr = new Array(t-f);
            for (let i=f; i< t; i++) arr[i-f] = this.getElement(i);
            return arr;
        }
        getElement(idx) {
            idx = parseInt(idx);
            const idx1 = Math.floor(idx / SUBARRAY_SIZE$1);
            const idx2 = idx % SUBARRAY_SIZE$1;
            return this.arr[idx1] ? this.arr[idx1][idx2] : undefined;
        }
        setElement(idx, value) {
            idx = parseInt(idx);
            const idx1 = Math.floor(idx / SUBARRAY_SIZE$1);
            if (!this.arr[idx1]) {
                this.arr[idx1] = new Array(SUBARRAY_SIZE$1);
            }
            const idx2 = idx % SUBARRAY_SIZE$1;
            this.arr[idx1][idx2] = value;
            if (idx >= this.length) this.length = idx+1;
            return true;
        }
        getKeys() {
            const newA = new BigArray$1();
            for (let i=0; i<this.arr.length; i++) {
                if (this.arr[i]) {
                    for (let j=0; j<this.arr[i].length; j++) {
                        if (typeof this.arr[i][j] !== "undefined") {
                            newA.push(i*SUBARRAY_SIZE$1+j);
                        }
                    }
                }
            }
            return newA;
        }
    }

    class BigArray$1 {
        constructor( initSize ) {
            const obj = new _BigArray$1(initSize);
            const extObj = new Proxy(obj, BigArrayHandler$1);
            return extObj;
        }
    }

    async function readR1csHeader(fd,sections,singleThread) {


        const res = {};
        await startReadUniqueSection(fd, sections, 1);
        // Read Header
        res.n8 = await fd.readULE32();
        res.prime = await readBigInt(fd, res.n8);

        res.curve = await getCurveFromR(res.prime, singleThread);

        res.nVars = await fd.readULE32();
        res.nOutputs = await fd.readULE32();
        res.nPubInputs = await fd.readULE32();
        res.nPrvInputs = await fd.readULE32();
        res.nLabels = await fd.readULE64();
        res.nConstraints = await fd.readULE32();
        await endReadSection(fd);

        return res;
    }

    async function readConstraints(fd,sections, r1cs, logger, loggerCtx) {
        const bR1cs = await readSection(fd, sections, 2);
        let bR1csPos = 0;
        let constraints;
        if (r1cs.nConstraints>1<<20) {
            constraints = new BigArray$1();
        } else {
            constraints = [];
        }
        for (let i=0; i<r1cs.nConstraints; i++) {
            if ((logger)&&(i%100000 == 0)) logger.info(`${loggerCtx}: Loading constraints: ${i}/${r1cs.nConstraints}`);
            const c = readConstraint();
            constraints.push(c);
        }
        return constraints;


        function readConstraint() {
            const c = [];
            c[0] = readLC();
            c[1] = readLC();
            c[2] = readLC();
            return c;
        }

        function readLC() {
            const lc= {};

            const buffUL32 = bR1cs.slice(bR1csPos, bR1csPos+4);
            bR1csPos += 4;
            const buffUL32V = new DataView(buffUL32.buffer);
            const nIdx = buffUL32V.getUint32(0, true);

            const buff = bR1cs.slice(bR1csPos, bR1csPos + (4+r1cs.n8)*nIdx );
            bR1csPos += (4+r1cs.n8)*nIdx;
            const buffV = new DataView(buff.buffer);
            for (let i=0; i<nIdx; i++) {
                const idx = buffV.getUint32(i*(4+r1cs.n8), true);
                const val = r1cs.curve.Fr.fromRprLE(buff, i*(4+r1cs.n8)+4);
                lc[idx] = val;
            }
            return lc;
        }
    }

    async function readMap(fd, sections, r1cs, logger, loggerCtx) {
        const bMap = await readSection(fd, sections, 3);
        let bMapPos = 0;
        let map;

        if (r1cs.nVars>1<<20) {
            map = new BigArray$1();
        } else {
            map = [];
        }
        for (let i=0; i<r1cs.nVars; i++) {
            if ((logger)&&(i%10000 == 0)) logger.info(`${loggerCtx}: Loading map: ${i}/${r1cs.nVars}`);
            const idx = readULE64();
            map.push(idx);
        }

        return map;

        function readULE64() {
            const buffULE64 = bMap.slice(bMapPos, bMapPos+8);
            bMapPos += 8;
            const buffULE64V = new DataView(buffULE64.buffer);
            const LSB = buffULE64V.getUint32(0, true);
            const MSB = buffULE64V.getUint32(4, true);

            return MSB * 0x100000000 + LSB;
        }

    }

    async function readR1cs(fileName, loadConstraints, loadMap, singleThread, logger, loggerCtx) {

        const {fd, sections} = await readBinFile(fileName, "r1cs", 1);

        const res = await readR1csHeader(fd, sections, singleThread);


        if (loadConstraints) {
            res.constraints = await readConstraints(fd, sections, res, logger, loggerCtx);
        }

        // Read Labels

        if (loadMap) {
            res.map = await readMap(fd, sections, res, logger, loggerCtx);
        }

        await fd.close();

        return res;
    }

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */

    const bls12381r = Scalar.e("73eda753299d7d483339d80809a1d80553bda402fffe5bfeffffffff00000001", 16);
    const bn128r = Scalar.e("21888242871839275222246405745257275088548364400416034343698204186575808495617");

    async function r1csInfo(r1csName, logger) {

        const cir = await readR1cs(r1csName);

        if (Scalar.eq(cir.prime, bn128r)) {
            if (logger) logger.info("Curve: bn-128");
        } else if (Scalar.eq(cir.prime, bls12381r)) {
            if (logger) logger.info("Curve: bls12-381");
        } else {
            if (logger) logger.info(`Unknown Curve. Prime: ${Scalar.toString(cir.prime)}`);
        }
        if (logger) logger.info(`# of Wires: ${cir.nVars}`);
        if (logger) logger.info(`# of Constraints: ${cir.nConstraints}`);
        if (logger) logger.info(`# of Private Inputs: ${cir.nPrvInputs}`);
        if (logger) logger.info(`# of Public Inputs: ${cir.nPubInputs}`);
        if (logger) logger.info(`# of Labels: ${cir.nLabels}`);
        if (logger) logger.info(`# of Outputs: ${cir.nOutputs}`);

        return cir;
    }

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */

    function stringifyBigInts$2(Fr, o) {
        if (o instanceof Uint8Array)  {
            return Fr.toString(o);
        } else if (Array.isArray(o)) {
            return o.map(stringifyBigInts$2.bind(null, Fr));
        } else if (typeof o == "object") {
            const res = {};
            const keys = Object.keys(o);
            keys.forEach( (k) => {
                res[k] = stringifyBigInts$2(Fr, o[k]);
            });
            return res;
        } else if ((typeof(o) == "bigint") || o.eq !== undefined)  {
            return o.toString(10);
        } else {
            return o;
        }
    }


    async function r1csExportJson(r1csFileName, logger) {

        const cir = await readR1cs(r1csFileName, true, true, true, logger);
        const Fr=cir.curve.Fr;
        delete cir.curve;

        return stringifyBigInts$2(Fr, cir);
    }

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */

    var r1cs = /*#__PURE__*/Object.freeze({
        __proto__: null,
        print: r1csPrint,
        info: r1csInfo,
        exportJson: r1csExportJson
    });

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */

    async function loadSymbols(symFileName) {
        const sym = {
            labelIdx2Name: [ "one" ],
            varIdx2Name: [ "one" ],
            componentIdx2Name: []
        };
        const fd = await readExisting(symFileName);
        const buff = await fd.read(fd.totalSize);
        const symsStr = new TextDecoder("utf-8").decode(buff);
        const lines = symsStr.split("\n");
        for (let i=0; i<lines.length; i++) {
            const arr = lines[i].split(",");
            if (arr.length!=4) continue;
            if (sym.varIdx2Name[arr[1]]) {
                sym.varIdx2Name[arr[1]] += "|" + arr[3];
            } else {
                sym.varIdx2Name[arr[1]] = arr[3];
            }
            sym.labelIdx2Name[arr[0]] = arr[3];
            if (!sym.componentIdx2Name[arr[2]]) {
                sym.componentIdx2Name[arr[2]] = extractComponent(arr[3]);
            }
        }

        await fd.close();

        return sym;

        function extractComponent(name) {
            const arr = name.split(".");
            arr.pop(); // Remove the lasr element
            return arr.join(".");
        }
    }

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */

    async function wtnsDebug(input, wasmFileName, wtnsFileName, symName, options, logger) {

        const fdWasm = await readExisting(wasmFileName);
        const wasm = await fdWasm.read(fdWasm.totalSize);
        await fdWasm.close();


        let wcOps = {
            sanityCheck: true
        };
        let sym = await loadSymbols(symName);
        if (options.set) {
            if (!sym) sym = await loadSymbols(symName);
            wcOps.logSetSignal= function(labelIdx, value) {
                if (logger) logger.info("SET " + sym.labelIdx2Name[labelIdx] + " <-- " + value.toString());
            };
        }
        if (options.get) {
            if (!sym) sym = await loadSymbols(symName);
            wcOps.logGetSignal= function(varIdx, value) {
                if (logger) logger.info("GET " + sym.labelIdx2Name[varIdx] + " --> " + value.toString());
            };
        }
        if (options.trigger) {
            if (!sym) sym = await loadSymbols(symName);
            wcOps.logStartComponent= function(cIdx) {
                if (logger) logger.info("START: " + sym.componentIdx2Name[cIdx]);
            };
            wcOps.logFinishComponent= function(cIdx) {
                if (logger) logger.info("FINISH: " + sym.componentIdx2Name[cIdx]);
            };
        }
        wcOps.sym = sym;

        const wc = await builder(wasm, wcOps);
        const w = await wc.calculateWitness(input);

        const fdWtns = await createBinFile(wtnsFileName, "wtns", 2, 2);

        await write(fdWtns, w, wc.prime);

        await fdWtns.close();
    }

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */

    async function wtnsExportJson(wtnsFileName) {

        const w = await read(wtnsFileName);

        return w;
    }

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */

    var wtns = /*#__PURE__*/Object.freeze({
        __proto__: null,
        calculate: wtnsCalculate,
        debug: wtnsDebug,
        exportJson: wtnsExportJson
    });

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */

    const SUBARRAY_SIZE = 0x40000;

    const BigArrayHandler = {
        get: function(obj, prop) {
            if (!isNaN(prop)) {
                return obj.getElement(prop);
            } else return obj[prop];
        },
        set: function(obj, prop, value) {
            if (!isNaN(prop)) {
                return obj.setElement(prop, value);
            } else {
                obj[prop] = value;
                return true;
            }
        }
    };

    class _BigArray {
        constructor (initSize) {
            this.length = initSize || 0;
            this.arr = new Array(SUBARRAY_SIZE);

            for (let i=0; i<initSize; i+=SUBARRAY_SIZE) {
                this.arr[i/SUBARRAY_SIZE] = new Array(Math.min(SUBARRAY_SIZE, initSize - i));
            }
            return this;
        }
        push () {
            for (let i=0; i<arguments.length; i++) {
                this.setElement (this.length, arguments[i]);
            }
        }

        slice (f, t) {
            const arr = new Array(t-f);
            for (let i=f; i< t; i++) arr[i-f] = this.getElement(i);
            return arr;
        }
        getElement(idx) {
            idx = parseInt(idx);
            const idx1 = Math.floor(idx / SUBARRAY_SIZE);
            const idx2 = idx % SUBARRAY_SIZE;
            return this.arr[idx1] ? this.arr[idx1][idx2] : undefined;
        }
        setElement(idx, value) {
            idx = parseInt(idx);
            const idx1 = Math.floor(idx / SUBARRAY_SIZE);
            if (!this.arr[idx1]) {
                this.arr[idx1] = new Array(SUBARRAY_SIZE);
            }
            const idx2 = idx % SUBARRAY_SIZE;
            this.arr[idx1][idx2] = value;
            if (idx >= this.length) this.length = idx+1;
            return true;
        }
        getKeys() {
            const newA = new BigArray();
            for (let i=0; i<this.arr.length; i++) {
                if (this.arr[i]) {
                    for (let j=0; j<this.arr[i].length; j++) {
                        if (typeof this.arr[i][j] !== "undefined") {
                            newA.push(i*SUBARRAY_SIZE+j);
                        }
                    }
                }
            }
            return newA;
        }
    }

    class BigArray {
        constructor( initSize ) {
            const obj = new _BigArray(initSize);
            const extObj = new Proxy(obj, BigArrayHandler);
            return extObj;
        }
    }

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */


    async function newZKey(r1csName, ptauName, zkeyName, logger) {

        const TAU_G1 = 0;
        const TAU_G2 = 1;
        const ALPHATAU_G1 = 2;
        const BETATAU_G1 = 3;
        await blake2bWasm.ready();
        const csHasher = blake2bWasm(64);

        const {fd: fdPTau, sections: sectionsPTau} = await readBinFile(ptauName, "ptau", 1);
        const {curve, power} = await readPTauHeader(fdPTau, sectionsPTau);
        const {fd: fdR1cs, sections: sectionsR1cs} = await readBinFile(r1csName, "r1cs", 1);
        const r1cs = await readR1csHeader(fdR1cs, sectionsR1cs, false);

        const sG1 = curve.G1.F.n8*2;
        const sG2 = curve.G2.F.n8*2;

        if (r1cs.prime != curve.r) {
            if (logger) logger.error("r1cs curve does not match powers of tau ceremony curve");
            return -1;
        }

        const cirPower = log2(r1cs.nConstraints + r1cs.nPubInputs + r1cs.nOutputs +1 -1) +1;

        if (cirPower > power) {
            if (logger) logger.error(`circuit too big for this power of tau ceremony. ${r1cs.nConstraints}*2 > 2**${power}`);
            return -1;
        }

        if (!sectionsPTau[12]) {
            if (logger) logger.error("Powers of tau is not prepared.");
            return -1;
        }

        const nPublic = r1cs.nOutputs + r1cs.nPubInputs;
        const domainSize = 2 ** cirPower;

        // Write the header
        ///////////
        const fdSection1 = await startWriteSectionFile(zkeyName, 1);
        await fdSection1.writeULE32(1); // Groth
        await endWriteSectionFile(fdSection1);


        // Write the Groth header section
        ///////////
        const fdSection2 = await startWriteSectionFile(zkeyName, 2);
        const primeQ = curve.q;
        const n8q = (Math.floor( (Scalar.bitLength(primeQ) - 1) / 64) +1)*8;

        const primeR = curve.r;
        const n8r = (Math.floor( (Scalar.bitLength(primeR) - 1) / 64) +1)*8;
        const Rr = Scalar.mod(Scalar.shl(1, n8r*8), primeR);
        const R2r = curve.Fr.e(Scalar.mod(Scalar.mul(Rr,Rr), primeR));

        await fdSection2.writeULE32(n8q);
        await writeBigInt(fdSection2, primeQ, n8q);
        await fdSection2.writeULE32(n8r);
        await writeBigInt(fdSection2, primeR, n8r);
        await fdSection2.writeULE32(r1cs.nVars);                         // Total number of bars
        await fdSection2.writeULE32(nPublic);                       // Total number of public vars (not including ONE)
        await fdSection2.writeULE32(domainSize);                  // domainSize

        let bAlpha1;
        bAlpha1 = await fdPTau.read(sG1, sectionsPTau[4][0].p);
        await fdSection2.write(bAlpha1);
        bAlpha1 = await curve.G1.batchLEMtoU(bAlpha1);
        csHasher.update(bAlpha1);

        let bBeta1;
        bBeta1 = await fdPTau.read(sG1, sectionsPTau[5][0].p);
        await fdSection2.write(bBeta1);
        bBeta1 = await curve.G1.batchLEMtoU(bBeta1);
        csHasher.update(bBeta1);

        let bBeta2;
        bBeta2 = await fdPTau.read(sG2, sectionsPTau[6][0].p);
        await fdSection2.write(bBeta2);
        bBeta2 = await curve.G2.batchLEMtoU(bBeta2);
        csHasher.update(bBeta2);

        const bg1 = new Uint8Array(sG1);
        curve.G1.toRprLEM(bg1, 0, curve.G1.g);
        const bg2 = new Uint8Array(sG2);
        curve.G2.toRprLEM(bg2, 0, curve.G2.g);
        const bg1U = new Uint8Array(sG1);
        curve.G1.toRprUncompressed(bg1U, 0, curve.G1.g);
        const bg2U = new Uint8Array(sG2);
        curve.G2.toRprUncompressed(bg2U, 0, curve.G2.g);

        await fdSection2.write(bg2);        // gamma2
        await fdSection2.write(bg1);        // delta1
        await fdSection2.write(bg2);        // delta2
        csHasher.update(bg2U);      // gamma2
        csHasher.update(bg1U);      // delta1
        csHasher.update(bg2U);      // delta2
        await endWriteSectionFile(fdSection2);

        if (logger) logger.info("Reading r1cs");
        let sR1cs = await readSection(fdR1cs, sectionsR1cs, 2);

        const A = new BigArray(r1cs.nVars);
        const B1 = new BigArray(r1cs.nVars);
        const B2 = new BigArray(r1cs.nVars);
        const C = new BigArray(r1cs.nVars- nPublic -1);
        const IC = new Array(nPublic+1);

        if (logger) logger.info("Reading tauG1");
        let sTauG1 = await readSection(fdPTau, sectionsPTau, 12, (domainSize -1)*sG1, domainSize*sG1);
        if (logger) logger.info("Reading tauG2");
        let sTauG2 = await readSection(fdPTau, sectionsPTau, 13, (domainSize -1)*sG2, domainSize*sG2);
        if (logger) logger.info("Reading alphatauG1");
        let sAlphaTauG1 = await readSection(fdPTau, sectionsPTau, 14, (domainSize -1)*sG1, domainSize*sG1);
        if (logger) logger.info("Reading betatauG1");
        let sBetaTauG1 = await readSection(fdPTau, sectionsPTau, 15, (domainSize -1)*sG1, domainSize*sG1);

        await processConstraints();

        await composeAndWritePoints(3, "G1", IC, "IC");

        await writeHs();

        await hashHPoints();

        await composeAndWritePoints(8, "G1", C, "C");
        await composeAndWritePoints(5, "G1", A, "A");
        await composeAndWritePoints(6, "G1", B1, "B1");
        await composeAndWritePoints(7, "G2", B2, "B2");

        const csHash = csHasher.digest();
        // Contributions section
        const fdSection10 = await startWriteSectionFile(zkeyName, 10);
        await fdSection10.write(csHash);
        await fdSection10.writeULE32(0);
        await endWriteSectionFile(fdSection10);

        if (logger) logger.info(formatHash(csHash, "Circuit hash: "));


        await fdR1cs.close();
        await fdPTau.close();

        return csHash;

        async function writeHs() {
            const buffOut = new BigBuffer(domainSize*sG1);
            if (cirPower < curve.Fr.s) {
                let sTauG1 = await readSection(fdPTau, sectionsPTau, 12, (domainSize*2-1)*sG1, domainSize*2*sG1);
                for (let i=0; i< domainSize; i++) {
                    if ((logger)&&(i%10000 == 0)) logger.debug(`spliting buffer: ${i}/${domainSize}`);
                    const buff = sTauG1.slice( (i*2+1)*sG1, (i*2+1)*sG1 + sG1 );
                    buffOut.set(buff, i*sG1);
                }
            } else if (cirPower == curve.Fr.s) {
                const o = sectionsPTau[12][0].p + ((2 ** (cirPower+1)) -1)*sG1;
                await fdPTau.readToBuffer(buffOut, 0, domainSize*sG1, o + domainSize*sG1);
            } else {
                if (logger) logger.error("Circuit too big");
                throw new Error("Circuit too big for this curve");
            }
            const fdSection9 = await startWriteSectionFile(zkeyName, 9);
            await fdSection9.write(buffOut);
            await endWriteSectionFile(fdSection9);
        }

        async function processConstraints() {
            const buffCoeff = new Uint8Array(12 + curve.Fr.n8);
            const buffCoeffV = new DataView(buffCoeff.buffer);
            const bOne = new Uint8Array(curve.Fr.n8);
            curve.Fr.toRprLE(bOne, 0, curve.Fr.e(1));

            let r1csPos = 0;

            function r1cs_readULE32() {
                const buff = sR1cs.slice(r1csPos, r1csPos+4);
                r1csPos += 4;
                const buffV = new DataView(buff.buffer);
                return buffV.getUint32(0, true);
            }

            const coefs = new BigArray();
            for (let c=0; c<r1cs.nConstraints; c++) {
                if ((logger)&&(c%10000 == 0)) logger.debug(`processing constraints: ${c}/${r1cs.nConstraints}`);
                const nA = r1cs_readULE32();
                for (let i=0; i<nA; i++) {
                    const s = r1cs_readULE32();
                    const coefp = r1csPos;
                    r1csPos += curve.Fr.n8;

                    const l1t = TAU_G1;
                    const l1 = sG1*c;
                    const l2t = BETATAU_G1;
                    const l2 = sG1*c;
                    if (typeof A[s] === "undefined") A[s] = [];
                    A[s].push([l1t, l1, coefp]);

                    if (s <= nPublic) {
                        if (typeof IC[s] === "undefined") IC[s] = [];
                        IC[s].push([l2t, l2, coefp]);
                    } else {
                        if (typeof C[s- nPublic -1] === "undefined") C[s- nPublic -1] = [];
                        C[s - nPublic -1].push([l2t, l2, coefp]);
                    }
                    coefs.push([0, c, s, coefp]);
                }

                const nB = r1cs_readULE32();
                for (let i=0; i<nB; i++) {
                    const s = r1cs_readULE32();
                    const coefp = r1csPos;
                    r1csPos += curve.Fr.n8;

                    const l1t = TAU_G1;
                    const l1 = sG1*c;
                    const l2t = TAU_G2;
                    const l2 = sG2*c;
                    const l3t = ALPHATAU_G1;
                    const l3 = sG1*c;
                    if (typeof B1[s] === "undefined") B1[s] = [];
                    B1[s].push([l1t, l1, coefp]);
                    if (typeof B2[s] === "undefined") B2[s] = [];
                    B2[s].push([l2t, l2, coefp]);

                    if (s <= nPublic) {
                        if (typeof IC[s] === "undefined") IC[s] = [];
                        IC[s].push([l3t, l3, coefp]);
                    } else {
                        if (typeof C[s- nPublic -1] === "undefined") C[s- nPublic -1] = [];
                        C[s- nPublic -1].push([l3t, l3, coefp]);
                    }

                    coefs.push([1, c, s, coefp]);
                }

                const nC = r1cs_readULE32();
                for (let i=0; i<nC; i++) {
                    const s = r1cs_readULE32();
                    const coefp = r1csPos;
                    r1csPos += curve.Fr.n8;

                    const l1t = TAU_G1;
                    const l1 = sG1*c;
                    if (s <= nPublic) {
                        if (typeof IC[s] === "undefined") IC[s] = [];
                        IC[s].push([l1t, l1, coefp]);
                    } else {
                        if (typeof C[s- nPublic -1] === "undefined") C[s- nPublic -1] = [];
                        C[s- nPublic -1].push([l1t, l1, coefp]);
                    }
                }
            }

            for (let s = 0; s <= nPublic ; s++) {
                const l1t = TAU_G1;
                const l1 = sG1*(r1cs.nConstraints + s);
                const l2t = BETATAU_G1;
                const l2 = sG1*(r1cs.nConstraints + s);
                if (typeof A[s] === "undefined") A[s] = [];
                A[s].push([l1t, l1, -1]);
                if (typeof IC[s] === "undefined") IC[s] = [];
                IC[s].push([l2t, l2, -1]);
                coefs.push([0, r1cs.nConstraints + s, s, -1]);
            }

            const buffSection = new BigBuffer(coefs.length*(12+curve.Fr.n8) + 4);

            const buff4 = new Uint8Array(4);
            const buff4V = new DataView(buff4.buffer);
            buff4V.setUint32(0, coefs.length, true);
            buffSection.set(buff4);
            let coefsPos = 4;
            for (let i=0; i<coefs.length; i++) {
                if ((logger)&&(i%100000 == 0)) logger.debug(`writing coeffs: ${i}/${coefs.length}`);
                writeCoef(coefs[i]);
            }

            const fdSection4 = await startWriteSectionFile(zkeyName, 4);
            await fdSection4.write(buffSection);
            await endWriteSectionFile(fdSection4);

            function writeCoef(c) {
                buffCoeffV.setUint32(0, c[0], true);
                buffCoeffV.setUint32(4, c[1], true);
                buffCoeffV.setUint32(8, c[2], true);
                let n;
                if (c[3]>=0) {
                    n = curve.Fr.fromRprLE(sR1cs.slice(c[3], c[3] + curve.Fr.n8), 0);
                } else {
                    n = curve.Fr.fromRprLE(bOne, 0);
                }
                const nR2 = curve.Fr.mul(n, R2r);
                curve.Fr.toRprLE(buffCoeff, 12, nR2);
                buffSection.set(buffCoeff, coefsPos);
                coefsPos += buffCoeff.length;
            }

        }

        async function composeAndWritePoints(idSection, groupName, arr, sectionName) {
            const CHUNK_SIZE= 1<<15;
            const G = curve[groupName];

            hashU32(arr.length);
            const fdSection = await startWriteSectionFile(zkeyName, idSection);

            let opPromises = [];

            let i=0;
            while (i<arr.length) {

                let t=0;
                while ((i<arr.length)&&(t<curve.tm.concurrency)) {
                    if (logger)  logger.debug(`Writing points start ${sectionName}: ${i}/${arr.length}`);
                    let n = 1;
                    let nP = (arr[i] ? arr[i].length : 0);
                    while ((i + n < arr.length) && (nP + (arr[i+n] ? arr[i+n].length : 0) < CHUNK_SIZE) && (n<CHUNK_SIZE)) {
                        nP += (arr[i+n] ? arr[i+n].length : 0);
                        n ++;
                    }
                    const subArr = arr.slice(i, i + n);
                    const _i = i;
                    opPromises.push(composeAndWritePointsThread(groupName, subArr, logger, sectionName).then( (r) => {
                        if (logger)  logger.debug(`Writing points end ${sectionName}: ${_i}/${arr.length}`);
                        return r;
                    }));
                    i += n;
                    t++;
                }

                const result = await Promise.all(opPromises);

                for (let k=0; k<result.length; k++) {
                    await fdSection.write(result[k][0]);
                    const buff = await G.batchLEMtoU(result[k][0]);
                    csHasher.update(buff);
                }
                opPromises = [];

            }
            await endWriteSectionFile(fdSection);

        }

        async function composeAndWritePointsThread(groupName, arr, logger, sectionName) {
            const G = curve[groupName];
            const sGin = G.F.n8*2;
            const sGmid = G.F.n8*3;
            const sGout = G.F.n8*2;
            let fnExp, fnMultiExp, fnBatchToAffine, fnZero;
            if (groupName == "G1") {
                fnExp = "g1m_timesScalarAffine";
                fnMultiExp = "g1m_multiexpAffine";
                fnBatchToAffine = "g1m_batchToAffine";
                fnZero = "g1m_zero";
            } else if (groupName == "G2") {
                fnExp = "g2m_timesScalarAffine";
                fnMultiExp = "g2m_multiexpAffine";
                fnBatchToAffine = "g2m_batchToAffine";
                fnZero = "g2m_zero";
            } else {
                throw new Error("Invalid group");
            }
            let acc =0;
            for (let i=0; i<arr.length; i++) acc += arr[i] ? arr[i].length : 0;
            let bBases, bScalars;
            if (acc> 2<<14) {
                bBases = new BigBuffer(acc*sGin);
                bScalars = new BigBuffer(acc*curve.Fr.n8);
            } else {
                bBases = new Uint8Array(acc*sGin);
                bScalars = new Uint8Array(acc*curve.Fr.n8);
            }
            let pB =0;
            let pS =0;

            const sBuffs = [
                sTauG1,
                sTauG2,
                sAlphaTauG1,
                sBetaTauG1
            ];

            const bOne = new Uint8Array(curve.Fr.n8);
            curve.Fr.toRprLE(bOne, 0, curve.Fr.e(1));

            let offset = 0;
            for (let i=0; i<arr.length; i++) {
                if (!arr[i]) continue;
                for (let j=0; j<arr[i].length; j++) {
                    if ((logger)&&(j)&&(j%10000 == 0))  logger.debug(`Configuring big array ${sectionName}: ${j}/${arr[i].length}`);
                    bBases.set(
                        sBuffs[arr[i][j][0]].slice(
                            arr[i][j][1],
                            arr[i][j][1] + sGin
                        ), offset*sGin
                    );
                    if (arr[i][j][2]>=0) {
                        bScalars.set(
                            sR1cs.slice(
                                arr[i][j][2],
                                arr[i][j][2] + curve.Fr.n8
                            ),
                            offset*curve.Fr.n8
                        );
                    } else {
                        bScalars.set(bOne, offset*curve.Fr.n8);
                    }
                    offset ++;
                }
            }

            if (arr.length>1) {
                const task = [];
                task.push({cmd: "ALLOCSET", var: 0, buff: bBases});
                task.push({cmd: "ALLOCSET", var: 1, buff: bScalars});
                task.push({cmd: "ALLOC", var: 2, len: arr.length*sGmid});
                pB = 0;
                pS = 0;
                let pD =0;
                for (let i=0; i<arr.length; i++) {
                    if (!arr[i]) {
                        task.push({cmd: "CALL", fnName: fnZero, params: [
                            {var: 2, offset: pD}
                        ]});
                        pD += sGmid;
                        continue;
                    }
                    if (arr[i].length == 1) {
                        task.push({cmd: "CALL", fnName: fnExp, params: [
                            {var: 0, offset: pB},
                            {var: 1, offset: pS},
                            {val: curve.Fr.n8},
                            {var: 2, offset: pD}
                        ]});
                    } else {
                        task.push({cmd: "CALL", fnName: fnMultiExp, params: [
                            {var: 0, offset: pB},
                            {var: 1, offset: pS},
                            {val: curve.Fr.n8},
                            {val: arr[i].length},
                            {var: 2, offset: pD}
                        ]});
                    }
                    pB += sGin*arr[i].length;
                    pS += curve.Fr.n8*arr[i].length;
                    pD += sGmid;
                }
                task.push({cmd: "CALL", fnName: fnBatchToAffine, params: [
                    {var: 2},
                    {val: arr.length},
                    {var: 2},
                ]});
                task.push({cmd: "GET", out: 0, var: 2, len: arr.length*sGout});

                const res = await curve.tm.queueAction(task);
                return res;
            } else {
                let res = await G.multiExpAffine(bBases, bScalars, logger, sectionName);
                res = [ G.toAffine(res) ];
                return res;
            }
        }


        async function hashHPoints() {
            const CHUNK_SIZE = 1<<14;

            hashU32(domainSize-1);

            for (let i=0; i<domainSize-1; i+= CHUNK_SIZE) {
                if (logger)  logger.debug(`HashingHPoints: ${i}/${domainSize}`);
                const n = Math.min(domainSize-1, CHUNK_SIZE);
                await hashHPointsChunk(i, n);
            }
        }

        async function hashHPointsChunk(offset, nPoints) {
            const buff1 = await fdPTau.read(nPoints *sG1, sectionsPTau[2][0].p + (offset + domainSize)*sG1);
            const buff2 = await fdPTau.read(nPoints *sG1, sectionsPTau[2][0].p + offset*sG1);
            const concurrency= curve.tm.concurrency;
            const nPointsPerThread = Math.floor(nPoints / concurrency);
            const opPromises = [];
            for (let i=0; i<concurrency; i++) {
                let n;
                if (i< concurrency-1) {
                    n = nPointsPerThread;
                } else {
                    n = nPoints - i*nPointsPerThread;
                }
                if (n==0) continue;

                const subBuff1 = buff1.slice(i*nPointsPerThread*sG1, (i*nPointsPerThread+n)*sG1);
                const subBuff2 = buff2.slice(i*nPointsPerThread*sG1, (i*nPointsPerThread+n)*sG1);
                opPromises.push(hashHPointsThread(subBuff1, subBuff2));
            }


            const result = await Promise.all(opPromises);

            for (let i=0; i<result.length; i++) {
                csHasher.update(result[i][0]);
            }
        }

        async function hashHPointsThread(buff1, buff2) {
            const nPoints = buff1.byteLength/sG1;
            const sGmid = curve.G1.F.n8*3;
            const task = [];
            task.push({cmd: "ALLOCSET", var: 0, buff: buff1});
            task.push({cmd: "ALLOCSET", var: 1, buff: buff2});
            task.push({cmd: "ALLOC", var: 2, len: nPoints*sGmid});
            for (let i=0; i<nPoints; i++) {
                task.push({
                    cmd: "CALL",
                    fnName: "g1m_subAffine",
                    params: [
                        {var: 0, offset: i*sG1},
                        {var: 1, offset: i*sG1},
                        {var: 2, offset: i*sGmid},
                    ]
                });
            }
            task.push({cmd: "CALL", fnName: "g1m_batchToAffine", params: [
                {var: 2},
                {val: nPoints},
                {var: 2},
            ]});
            task.push({cmd: "CALL", fnName: "g1m_batchLEMtoU", params: [
                {var: 2},
                {val: nPoints},
                {var: 2},
            ]});
            task.push({cmd: "GET", out: 0, var: 2, len: nPoints*sG1});

            const res = await curve.tm.queueAction(task);

            return res;
        }

        function hashU32(n) {
            const buff = new Uint8Array(4);
            const buffV = new DataView(buff.buffer, buff.byteOffset, buff.byteLength);
            buffV.setUint32(0, n, false);
            csHasher.update(buff);
        }

    }

    async function phase2exportMPCParams(zkeyName, mpcparamsName, logger) {

        const {fd: fdZKey, sections: sectionsZKey} = await readBinFile(zkeyName, "zkey", 2);
        const zkey = await readHeader$1(fdZKey, sectionsZKey);
        if (zkey.protocol != "groth16") {
            throw new Error("zkey file is not groth16");
        }

        const curve = await getCurveFromQ(zkey.q);
        const sG1 = curve.G1.F.n8*2;
        const sG2 = curve.G2.F.n8*2;

        const mpcParams = await readMPCParams(fdZKey, curve, sectionsZKey);

        const fdMPCParams = await createOverride(mpcparamsName);

        /////////////////////
        // Verification Key Section
        /////////////////////
        await writeG1(zkey.vk_alpha_1);
        await writeG1(zkey.vk_beta_1);
        await writeG2(zkey.vk_beta_2);
        await writeG2(zkey.vk_gamma_2);
        await writeG1(zkey.vk_delta_1);
        await writeG2(zkey.vk_delta_2);

        // IC
        let buffBasesIC;
        buffBasesIC = await readSection(fdZKey, sectionsZKey, 3);
        buffBasesIC = await curve.G1.batchLEMtoU(buffBasesIC);

        await writePointArray("G1", buffBasesIC);

        /////////////////////
        // h Section
        /////////////////////
        const buffBasesH_Lodd = await readSection(fdZKey, sectionsZKey, 9);

        let buffBasesH_Tau;
        buffBasesH_Tau = await curve.G1.fft(buffBasesH_Lodd, "affine", "jacobian", logger);
        buffBasesH_Tau = await curve.G1.batchApplyKey(buffBasesH_Tau, curve.Fr.neg(curve.Fr.e(2)), curve.Fr.w[zkey.power+1], "jacobian", "affine", logger);

        // Remove last element.  (The degree of H will be allways m-2)
        buffBasesH_Tau = buffBasesH_Tau.slice(0, buffBasesH_Tau.byteLength - sG1);
        buffBasesH_Tau = await curve.G1.batchLEMtoU(buffBasesH_Tau);
        await writePointArray("G1", buffBasesH_Tau);

        /////////////////////
        // L section
        /////////////////////
        let buffBasesC;
        buffBasesC = await readSection(fdZKey, sectionsZKey, 8);
        buffBasesC = await curve.G1.batchLEMtoU(buffBasesC);
        await writePointArray("G1", buffBasesC);

        /////////////////////
        // A Section (C section)
        /////////////////////
        let buffBasesA;
        buffBasesA = await readSection(fdZKey, sectionsZKey, 5);
        buffBasesA = await curve.G1.batchLEMtoU(buffBasesA);
        await writePointArray("G1", buffBasesA);

        /////////////////////
        // B1 Section
        /////////////////////
        let buffBasesB1;
        buffBasesB1 = await readSection(fdZKey, sectionsZKey, 6);
        buffBasesB1 = await curve.G1.batchLEMtoU(buffBasesB1);
        await writePointArray("G1", buffBasesB1);

        /////////////////////
        // B2 Section
        /////////////////////
        let buffBasesB2;
        buffBasesB2 = await readSection(fdZKey, sectionsZKey, 7);
        buffBasesB2 = await curve.G2.batchLEMtoU(buffBasesB2);
        await writePointArray("G2", buffBasesB2);

        await fdMPCParams.write(mpcParams.csHash);
        await writeU32(mpcParams.contributions.length);

        for (let i=0; i<mpcParams.contributions.length; i++) {
            const c = mpcParams.contributions[i];
            await writeG1(c.deltaAfter);
            await writeG1(c.delta.g1_s);
            await writeG1(c.delta.g1_sx);
            await writeG2(c.delta.g2_spx);
            await fdMPCParams.write(c.transcript);
        }

        await fdZKey.close();
        await fdMPCParams.close();

        async function writeG1(P) {
            const buff = new Uint8Array(sG1);
            curve.G1.toRprUncompressed(buff, 0, P);
            await fdMPCParams.write(buff);
        }

        async function writeG2(P) {
            const buff = new Uint8Array(sG2);
            curve.G2.toRprUncompressed(buff, 0, P);
            await fdMPCParams.write(buff);
        }

        async function writePointArray(groupName, buff) {
            let sG;
            if (groupName == "G1") {
                sG = sG1;
            } else {
                sG = sG2;
            }

            const buffSize = new Uint8Array(4);
            const buffSizeV = new DataView(buffSize.buffer, buffSize.byteOffset, buffSize.byteLength);
            buffSizeV.setUint32(0, buff.byteLength / sG, false);

            await fdMPCParams.write(buffSize);
            await fdMPCParams.write(buff);
        }

        async function writeU32(n) {
            const buffSize = new Uint8Array(4);
            const buffSizeV = new DataView(buffSize.buffer, buffSize.byteOffset, buffSize.byteLength);
            buffSizeV.setUint32(0, n, false);

            await fdMPCParams.write(buffSize);
        }



    }

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */

    async function phase2importMPCParams(zkeyNameOld, mpcparamsName, zkeyNameNew, name, logger) {

        const {fd: fdZKeyOld, sections: sectionsZKeyOld} = await readBinFile(zkeyNameOld, "zkey", 2);
        const zkeyHeader = await readHeader$1(fdZKeyOld, sectionsZKeyOld);
        if (zkeyHeader.protocol != "groth16") {
            throw new Error("zkey file is not groth16");
        }

        const curve = await getCurveFromQ(zkeyHeader.q);
        const sG1 = curve.G1.F.n8*2;
        const sG2 = curve.G2.F.n8*2;

        const oldMPCParams = await readMPCParams(fdZKeyOld, curve, sectionsZKeyOld);
        const newMPCParams = {};

        const fdMPCParams = await readExisting(mpcparamsName);

        fdMPCParams.pos =
            sG1*3 + sG2*3 +                     // vKey
            8 + sG1*zkeyHeader.nVars +              // IC + C
            4 + sG1*(zkeyHeader.domainSize-1) +     // H
            4 + sG1*zkeyHeader.nVars +              // A
            4 + sG1*zkeyHeader.nVars +              // B1
            4 + sG2*zkeyHeader.nVars;               // B2

        // csHash
        newMPCParams.csHash =  await fdMPCParams.read(64);

        const nConttributions = await fdMPCParams.readUBE32();
        newMPCParams.contributions = [];
        for (let i=0; i<nConttributions; i++) {
            const c = { delta:{} };
            c.deltaAfter = await readG1(fdMPCParams);
            c.delta.g1_s = await readG1(fdMPCParams);
            c.delta.g1_sx = await readG1(fdMPCParams);
            c.delta.g2_spx = await readG2(fdMPCParams);
            c.transcript = await fdMPCParams.read(64);
            if (i<oldMPCParams.contributions.length) {
                c.type = oldMPCParams.contributions[i].type;
                if (c.type==1) {
                    c.beaconHash = oldMPCParams.contributions[i].beaconHash;
                    c.numIterationsExp = oldMPCParams.contributions[i].numIterationsExp;
                }
                if (oldMPCParams.contributions[i].name) {
                    c.name = oldMPCParams.contributions[i].name;
                }
            }
            newMPCParams.contributions.push(c);
        }

        if (!hashIsEqual(newMPCParams.csHash, oldMPCParams.csHash)) {
            if (logger) logger.error("Hash of the original circuit does not match with the MPC one");
            return false;
        }

        if (oldMPCParams.contributions.length > newMPCParams.contributions.length) {
            if (logger) logger.error("The impoerted file does not include new contributions");
            return false;
        }

        for (let i=0; i<oldMPCParams.contributions.length; i++) {
            if (!contributionIsEqual(oldMPCParams.contributions[i], newMPCParams.contributions[i])) {
                if (logger) logger.error(`Previos contribution ${i} does not match`);
                return false;
            }
        }


        // Set the same name to all new controbutions
        if (name) {
            for (let i=oldMPCParams.contributions.length; i<newMPCParams.contributions.length; i++) {
                newMPCParams.contributions[i].name = name;
            }
        }

        const fdZKeyNew = await createBinFile(zkeyNameNew, "zkey", 1, 10);
        fdMPCParams.pos = 0;

        // Header
        fdMPCParams.pos += sG1;  // ignore alpha1 (keep original)
        fdMPCParams.pos += sG1;  // ignore beta1
        fdMPCParams.pos += sG2;  // ignore beta2
        fdMPCParams.pos += sG2;  // ignore gamma2
        zkeyHeader.vk_delta_1 = await readG1(fdMPCParams);
        zkeyHeader.vk_delta_2 = await readG2(fdMPCParams);
        await writeHeader(fdZKeyNew, zkeyHeader);

        // IC (Keep original)
        const nIC = await fdMPCParams.readUBE32();
        if (nIC != zkeyHeader.nPublic +1) {
            if (logger) logger.error("Invalid number of points in IC");
            await fdZKeyNew.discard();
            return false;
        }
        fdMPCParams.pos += sG1*(zkeyHeader.nPublic+1);
        await copySection(fdZKeyOld, sectionsZKeyOld, fdZKeyNew, 3);

        // Coeffs (Keep original)
        await copySection(fdZKeyOld, sectionsZKeyOld, fdZKeyNew, 4);

        // H Section
        const nH = await fdMPCParams.readUBE32();
        if (nH != zkeyHeader.domainSize-1) {
            if (logger) logger.error("Invalid number of points in H");
            await fdZKeyNew.discard();
            return false;
        }
        let buffH;
        const buffTauU = await fdMPCParams.read(sG1*(zkeyHeader.domainSize-1));
        const buffTauLEM = await curve.G1.batchUtoLEM(buffTauU);
        buffH = new Uint8Array(zkeyHeader.domainSize*sG1);
        buffH.set(buffTauLEM);   // Let the last one to zero.
        curve.G1.toRprLEM(buffH, sG1*(zkeyHeader.domainSize-1), curve.G1.zeroAffine);
        const n2Inv = curve.Fr.neg(curve.Fr.inv(curve.Fr.e(2)));
        const wInv = curve.Fr.inv(curve.Fr.w[zkeyHeader.power+1]);
        buffH = await curve.G1.batchApplyKey(buffH, n2Inv, wInv, "affine", "jacobian", logger);
        buffH = await curve.G1.ifft(buffH, "jacobian", "affine", logger);
        await startWriteSection(fdZKeyNew, 9);
        await fdZKeyNew.write(buffH);
        await endWriteSection(fdZKeyNew);

        // C Secion (L section)
        const nL = await fdMPCParams.readUBE32();
        if (nL != (zkeyHeader.nVars-zkeyHeader.nPublic-1)) {
            if (logger) logger.error("Invalid number of points in L");
            await fdZKeyNew.discard();
            return false;
        }
        let buffL;
        buffL = await fdMPCParams.read(sG1*(zkeyHeader.nVars-zkeyHeader.nPublic-1));
        buffL = await curve.G1.batchUtoLEM(buffL);
        await startWriteSection(fdZKeyNew, 8);
        await fdZKeyNew.write(buffL);
        await endWriteSection(fdZKeyNew);

        // A Section
        const nA = await fdMPCParams.readUBE32();
        if (nA != zkeyHeader.nVars) {
            if (logger) logger.error("Invalid number of points in A");
            await fdZKeyNew.discard();
            return false;
        }
        fdMPCParams.pos += sG1*(zkeyHeader.nVars);
        await copySection(fdZKeyOld, sectionsZKeyOld, fdZKeyNew, 5);

        // B1 Section
        const nB1 = await fdMPCParams.readUBE32();
        if (nB1 != zkeyHeader.nVars) {
            if (logger) logger.error("Invalid number of points in B1");
            await fdZKeyNew.discard();
            return false;
        }
        fdMPCParams.pos += sG1*(zkeyHeader.nVars);
        await copySection(fdZKeyOld, sectionsZKeyOld, fdZKeyNew, 6);

        // B2 Section
        const nB2 = await fdMPCParams.readUBE32();
        if (nB2 != zkeyHeader.nVars) {
            if (logger) logger.error("Invalid number of points in B2");
            await fdZKeyNew.discard();
            return false;
        }
        fdMPCParams.pos += sG2*(zkeyHeader.nVars);
        await copySection(fdZKeyOld, sectionsZKeyOld, fdZKeyNew, 7);

        await writeMPCParams(fdZKeyNew, curve, newMPCParams);

        await fdMPCParams.close();
        await fdZKeyNew.close();
        await fdZKeyOld.close();

        return true;

        async function readG1(fd) {
            const buff = await fd.read(curve.G1.F.n8*2);
            return curve.G1.fromRprUncompressed(buff, 0);
        }

        async function readG2(fd) {
            const buff = await fd.read(curve.G2.F.n8*2);
            return curve.G2.fromRprUncompressed(buff, 0);
        }


        function contributionIsEqual(c1, c2) {
            if (!curve.G1.eq(c1.deltaAfter   , c2.deltaAfter)) return false;
            if (!curve.G1.eq(c1.delta.g1_s   , c2.delta.g1_s)) return false;
            if (!curve.G1.eq(c1.delta.g1_sx  , c2.delta.g1_sx)) return false;
            if (!curve.G2.eq(c1.delta.g2_spx , c2.delta.g2_spx)) return false;
            if (!hashIsEqual(c1.transcript, c2.transcript)) return false;
            return true;
        }


    }

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */
    const sameRatio = sameRatio$2;



    async function phase2verifyFromInit(initFileName, pTauFileName, zkeyFileName, logger) {

        let sr;
        await blake2bWasm.ready();
        const maxZKeyVersion = 2;

        const zkey = await readHeader$1(zkeyFileName, maxZKeyVersion);
        if (zkey.protocol != "groth16") {
            throw new Error("zkey file is not groth16");
        }

        const curve = await getCurveFromQ(zkey.q);
        const sG1 = curve.G1.F.n8*2;

        const mpcParams = await readMPCParams(zkeyFileName, maxZKeyVersion, curve);

        const accumulatedHasher = blake2bWasm(64);
        accumulatedHasher.update(mpcParams.csHash);
        let curDelta = curve.G1.g;
        for (let i=0; i<mpcParams.contributions.length; i++) {
            const c = mpcParams.contributions[i];
            const ourHasher = cloneHasher(accumulatedHasher);

            hashG1(ourHasher, curve, c.delta.g1_s);
            hashG1(ourHasher, curve, c.delta.g1_sx);

            if (!hashIsEqual(ourHasher.digest(), c.transcript)) {
                console.log(`INVALID(${i}): Inconsistent transcript `);
                return false;
            }

            const delta_g2_sp = hashToG2(curve, c.transcript);

            sr = await sameRatio(curve, c.delta.g1_s, c.delta.g1_sx, delta_g2_sp, c.delta.g2_spx);
            if (sr !== true) {
                console.log(`INVALID(${i}): public key G1 and G2 do not have the same ration `);
                return false;
            }

            sr = await sameRatio(curve, curDelta, c.deltaAfter, delta_g2_sp, c.delta.g2_spx);
            if (sr !== true) {
                console.log(`INVALID(${i}): deltaAfter does not fillow the public key `);
                return false;
            }

            if (c.type == 1) {
                const rng = rngFromBeaconParams(c.beaconHash, c.numIterationsExp);
                const expected_prvKey = curve.Fr.fromRng(rng);
                const expected_g1_s = curve.G1.toAffine(curve.G1.fromRng(rng));
                const expected_g1_sx = curve.G1.toAffine(curve.G1.timesFr(expected_g1_s, expected_prvKey));
                if (curve.G1.eq(expected_g1_s, c.delta.g1_s) !== true) {
                    console.log(`INVALID(${i}): Key of the beacon does not match. g1_s `);
                    return false;
                }
                if (curve.G1.eq(expected_g1_sx, c.delta.g1_sx) !== true) {
                    console.log(`INVALID(${i}): Key of the beacon does not match. g1_sx `);
                    return false;
                }
            }

            hashPubKey(accumulatedHasher, curve, c);

            const contributionHasher = blake2bWasm(64);
            hashPubKey(contributionHasher, curve, c);

            c.contributionHash = contributionHasher.digest();

            curDelta = c.deltaAfter;
        }


        const zkeyInit = await readHeader$1(initFileName, maxZKeyVersion);

        if (zkeyInit.protocol != "groth16") {
            throw new Error("zkeyinit file is not groth16");
        }

        if (  (!Scalar.eq(zkeyInit.q, zkey.q))
            ||(!Scalar.eq(zkeyInit.r, zkey.r))
            ||(zkeyInit.n8q != zkey.n8q)
            ||(zkeyInit.n8r != zkey.n8r))
        {
            if (logger) logger.error("INVALID:  Different curves");
            return false;
        }

        if (  (zkeyInit.nVars != zkey.nVars)
            ||(zkeyInit.nPublic !=  zkey.nPublic)
            ||(zkeyInit.domainSize != zkey.domainSize))
        {
            if (logger) logger.error("INVALID:  Different circuit parameters");
            return false;
        }

        if (!curve.G1.eq(zkey.vk_alpha_1, zkeyInit.vk_alpha_1)) {
            if (logger) logger.error("INVALID:  Invalid alpha1");
            return false;
        }
        if (!curve.G1.eq(zkey.vk_beta_1, zkeyInit.vk_beta_1)) {
            if (logger) logger.error("INVALID:  Invalid beta1");
            return false;
        }
        if (!curve.G2.eq(zkey.vk_beta_2, zkeyInit.vk_beta_2)) {
            if (logger) logger.error("INVALID:  Invalid beta2");
            return false;
        }
        if (!curve.G2.eq(zkey.vk_gamma_2, zkeyInit.vk_gamma_2)) {
            if (logger) logger.error("INVALID:  Invalid gamma2");
            return false;
        }
        if (!curve.G1.eq(zkey.vk_delta_1, curDelta)) {
            if (logger) logger.error("INVALID:  Invalid delta1");
            return false;
        }
        sr = await sameRatio(curve, curve.G1.g, curDelta, curve.G2.g, zkey.vk_delta_2);
        if (sr !== true) {
            if (logger) logger.error("INVALID:  Invalid delta2");
            return false;
        }

        const mpcParamsInit = await readMPCParams(initFileName, maxZKeyVersion, curve);
        if (!hashIsEqual(mpcParams.csHash, mpcParamsInit.csHash)) {
            if (logger) logger.error("INVALID:  Circuit does not match");
            return false;
        }

        let ss;
        ss = await sectionFileIsEqual(initFileName, zkeyFileName, 3, maxZKeyVersion);
        if (!ss) {
            if (logger) logger.error("INVALID:  IC section is not identical");
            return false;
        }

        ss = await sectionFileIsEqual(initFileName, zkeyFileName, 4, maxZKeyVersion);
        if (!ss) {
            if (logger) logger.error("Coeffs section is not identical");
            return false;
        }

        ss = await sectionFileIsEqual(initFileName, zkeyFileName, 5, maxZKeyVersion);
        if (!ss) {
            if (logger) logger.error("A section is not identical");
            return false;
        }

        ss = await sectionFileIsEqual(initFileName, zkeyFileName, 6, maxZKeyVersion);
        if (!ss) {
            if (logger) logger.error("B1 section is not identical");
            return false;
        }

        ss = await sectionFileIsEqual(initFileName, zkeyFileName, 7, maxZKeyVersion);
        if (!ss) {
            if (logger) logger.error("B2 section is not identical");
            return false;
        }

        // Check L
        sr = await sectionHasSameRatio("G1", initFileName, zkeyFileName, maxZKeyVersion, 8, zkey.vk_delta_2, zkeyInit.vk_delta_2, "L section");
        if (sr!==true) {
            if (logger) logger.error("L section does not match");
            return false;
        }

        // Check H
        sr = await sameRatioH();
        if (sr!==true) {
            if (logger) logger.error("H section does not match");
            return false;
        }

        if (logger) logger.info(formatHash(mpcParams.csHash, "Circuit Hash: "));

        for (let i=mpcParams.contributions.length-1; i>=0; i--) {
            const c = mpcParams.contributions[i];
            if (logger) logger.info("-------------------------");
            if (logger) logger.info(formatHash(c.contributionHash, `contribution #${i+1} ${c.name ? c.name : ""}:`));
            if (c.type == 1) {
                if (logger) logger.info(`Beacon generator: ${byteArray2hex(c.beaconHash)}`);
                if (logger) logger.info(`Beacon iterations Exp: ${c.numIterationsExp}`);
            }
        }
        if (logger) logger.info("-------------------------");

        if (logger) logger.info("ZKey Ok!");

        return true;


        async function sectionHasSameRatio(groupName, initFileName, zkeyFileName, maxZKeyVersion, idSection, g2sp, g2spx, sectionName) {
            const MAX_CHUNK_SIZE = 1<<20;
            const G = curve[groupName];
            const sG = G.F.n8*2;
            const fdOld = await startReadSectionFile(initFileName, idSection, maxZKeyVersion);
            const fdNew = await startReadSectionFile(zkeyFileName, idSection, maxZKeyVersion);

            let R1 = G.zero;
            let R2 = G.zero;

            const nPoints = fdOld.readingSection.size / sG;

            for (let i=0; i<nPoints; i += MAX_CHUNK_SIZE) {
                if (logger) logger.debug(`Same ratio check ${sectionName}:  ${i}/${nPoints}`);
                const n = Math.min(nPoints - i, MAX_CHUNK_SIZE);
                const bases1 = await fdOld.read(n*sG);
                const bases2 = await fdNew.read(n*sG);

                const scalars = new Uint8Array(4*n);
                crypto.randomFillSync(scalars);


                const r1 = await G.multiExpAffine(bases1, scalars);
                const r2 = await G.multiExpAffine(bases2, scalars);

                R1 = G.add(R1, r1);
                R2 = G.add(R2, r2);
            }
            await endReadSectionFile(fdOld);
            await endReadSectionFile(fdNew);

            if (nPoints == 0) return true;

            sr = await sameRatio(curve, R1, R2, g2sp, g2spx);
            if (sr !== true) return false;

            return true;
        }

        async function sameRatioH() {
            const MAX_CHUNK_SIZE = 1<<20;
            const G = curve.G1;
            const Fr = curve.Fr;
            const sG = G.F.n8*2;

            const {fd: fdPTau, sections: sectionsPTau} = await readBinFile(pTauFileName, "ptau", 1);

            let buff_r = new BigBuffer(zkey.domainSize * zkey.n8r);

            const seed= new Array(8);
            for (let i=0; i<8; i++) {
                seed[i] = crypto.randomBytes(4).readUInt32BE(0, true);
            }
            const rng = new ChaCha(seed);
            for (let i=0; i<zkey.domainSize-1; i++) {   // Note that last one is zero
                const e = Fr.fromRng(rng);
                Fr.toRprLE(buff_r, i*zkey.n8r, e);
            }
            Fr.toRprLE(buff_r, (zkey.domainSize-1)*zkey.n8r, Fr.zero);

            let R1 = G.zero;
            for (let i=0; i<zkey.domainSize; i += MAX_CHUNK_SIZE) {
                if (logger) logger.debug(`H Verificaition(tau):  ${i}/${zkey.domainSize}`);
                const n = Math.min(zkey.domainSize - i, MAX_CHUNK_SIZE);

                const buff1 = await fdPTau.read(sG*n, sectionsPTau[2][0].p + zkey.domainSize*sG + i*sG);
                const buff2 = await fdPTau.read(sG*n, sectionsPTau[2][0].p + i*sG);

                const buffB = await batchSubstract(buff1, buff2);
                const buffS = buff_r.slice(i*zkey.n8r, (i+n)*zkey.n8r);
                const r = await G.multiExpAffine(buffB, buffS);

                R1 = G.add(R1, r);
            }

            // Caluclate odd coeficients in transformed domain

            buff_r = await Fr.batchToMontgomery(buff_r);
            // const first = curve.Fr.neg(curve.Fr.inv(curve.Fr.e(2)));
            // Works*2   const first = curve.Fr.neg(curve.Fr.e(2));


            let first;

            if (zkey.power < Fr.s) {
                first = Fr.neg(Fr.e(2));
            } else {
                const small_m  = 2 ** Fr.s;
                const shift_to_small_m = Fr.exp(Fr.shift, small_m);
                first = Fr.sub( shift_to_small_m, Fr.one);
            }

            // const inc = curve.Fr.inv(curve.PFr.w[zkey.power+1]);
            const inc = zkey.power < Fr.s ? Fr.w[zkey.power+1] : Fr.shift;
            buff_r = await Fr.batchApplyKey(buff_r, first, inc);
            buff_r = await Fr.fft(buff_r);
            buff_r = await Fr.batchFromMontgomery(buff_r);

            const fd = await startReadSectionFile(zkeyFileName, 9, maxZKeyVersion);

            let R2 = G.zero;
            for (let i=0; i<zkey.domainSize; i += MAX_CHUNK_SIZE) {
                if (logger) logger.debug(`H Verificaition(lagrange):  ${i}/${zkey.domainSize}`);
                const n = Math.min(zkey.domainSize - i, MAX_CHUNK_SIZE);

                const buff = await fd.read(sG*n);
                const buffS = buff_r.slice(i*zkey.n8r, (i+n)*zkey.n8r);
                const r = await G.multiExpAffine(buff, buffS);

                R2 = G.add(R2, r);
            }
            await endReadSectionFile(fd);

            sr = await sameRatio(curve, R1, R2, zkey.vk_delta_2, zkeyInit.vk_delta_2);
            if (sr !== true) return false;


            return true;

        }

        async function batchSubstract(buff1, buff2) {
            const sG = curve.G1.F.n8*2;
            const nPoints = buff1.byteLength / sG;
            const concurrency= curve.tm.concurrency;
            const nPointsPerThread = Math.floor(nPoints / concurrency);
            const opPromises = [];
            for (let i=0; i<concurrency; i++) {
                let n;
                if (i< concurrency-1) {
                    n = nPointsPerThread;
                } else {
                    n = nPoints - i*nPointsPerThread;
                }
                if (n==0) continue;

                const subBuff1 = buff1.slice(i*nPointsPerThread*sG1, (i*nPointsPerThread+n)*sG1);
                const subBuff2 = buff2.slice(i*nPointsPerThread*sG1, (i*nPointsPerThread+n)*sG1);
                opPromises.push(batchSubstractThread(subBuff1, subBuff2));
            }


            const result = await Promise.all(opPromises);

            const fullBuffOut = new Uint8Array(nPoints*sG);
            let p =0;
            for (let i=0; i<result.length; i++) {
                fullBuffOut.set(result[i][0], p);
                p+=result[i][0].byteLength;
            }

            return fullBuffOut;
        }


        async function batchSubstractThread(buff1, buff2) {
            const sG1 = curve.G1.F.n8*2;
            const sGmid = curve.G1.F.n8*3;
            const nPoints = buff1.byteLength/sG1;
            const task = [];
            task.push({cmd: "ALLOCSET", var: 0, buff: buff1});
            task.push({cmd: "ALLOCSET", var: 1, buff: buff2});
            task.push({cmd: "ALLOC", var: 2, len: nPoints*sGmid});
            for (let i=0; i<nPoints; i++) {
                task.push({
                    cmd: "CALL",
                    fnName: "g1m_subAffine",
                    params: [
                        {var: 0, offset: i*sG1},
                        {var: 1, offset: i*sG1},
                        {var: 2, offset: i*sGmid},
                    ]
                });
            }
            task.push({cmd: "CALL", fnName: "g1m_batchToAffine", params: [
                {var: 2},
                {val: nPoints},
                {var: 2},
            ]});
            task.push({cmd: "GET", out: 0, var: 2, len: nPoints*sG1});

            const res = await curve.tm.queueAction(task);

            return res;
        }

    }

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */

    async function phase2verifyFromR1cs(r1csFileName, pTauFileName, zkeyFileName, logger) {

        const initFileName = "~" + zkeyFileName + ".init";
        await newZKey(r1csFileName, pTauFileName, initFileName, logger);

        return await phase2verifyFromInit(initFileName, pTauFileName, zkeyFileName, logger);
    }

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */

    async function phase2contribute(zkeyNameOld, zkeyNameNew, name, entropy, logger) {
        await blake2bWasm.ready();

        const {fd: fdOld, sections: sections} = await readBinFile(zkeyNameOld, "zkey", 2);
        const zkey = await readHeader$1(fdOld, sections);
        if (zkey.protocol != "groth16") {
            throw new Error("zkey file is not groth16");
        }

        const curve = await getCurveFromQ(zkey.q);

        const mpcParams = await readMPCParams(fdOld, curve, sections);

        const fdNew = await createBinFile(zkeyNameNew, "zkey", 1, 10);


        const rng = await getRandomRng(entropy);

        const transcriptHasher = blake2bWasm(64);
        transcriptHasher.update(mpcParams.csHash);
        for (let i=0; i<mpcParams.contributions.length; i++) {
            hashPubKey(transcriptHasher, curve, mpcParams.contributions[i]);
        }

        const curContribution = {};
        curContribution.delta = {};
        curContribution.delta.prvKey = curve.Fr.fromRng(rng);
        curContribution.delta.g1_s = curve.G1.toAffine(curve.G1.fromRng(rng));
        curContribution.delta.g1_sx = curve.G1.toAffine(curve.G1.timesFr(curContribution.delta.g1_s, curContribution.delta.prvKey));
        hashG1(transcriptHasher, curve, curContribution.delta.g1_s);
        hashG1(transcriptHasher, curve, curContribution.delta.g1_sx);
        curContribution.transcript = transcriptHasher.digest();
        curContribution.delta.g2_sp = hashToG2(curve, curContribution.transcript);
        curContribution.delta.g2_spx = curve.G2.toAffine(curve.G2.timesFr(curContribution.delta.g2_sp, curContribution.delta.prvKey));

        zkey.vk_delta_1 = curve.G1.timesFr(zkey.vk_delta_1, curContribution.delta.prvKey);
        zkey.vk_delta_2 = curve.G2.timesFr(zkey.vk_delta_2, curContribution.delta.prvKey);

        curContribution.deltaAfter = zkey.vk_delta_1;

        curContribution.type = 0;
        if (name) curContribution.name = name;

        mpcParams.contributions.push(curContribution);

        await writeHeader(fdNew, zkey);

        // IC
        await copySection(fdOld, sections, fdNew, 3);

        // Coeffs (Keep original)
        await copySection(fdOld, sections, fdNew, 4);

        // A Section
        await copySection(fdOld, sections, fdNew, 5);

        // B1 Section
        await copySection(fdOld, sections, fdNew, 6);

        // B2 Section
        await copySection(fdOld, sections, fdNew, 7);

        const invDelta = curve.Fr.inv(curContribution.delta.prvKey);
        await applyKeyToSection(fdOld, sections, fdNew, 8, curve, "G1", invDelta, curve.Fr.e(1), "L Section", logger);
        await applyKeyToSection(fdOld, sections, fdNew, 9, curve, "G1", invDelta, curve.Fr.e(1), "H Section", logger);

        await writeMPCParams(fdNew, curve, mpcParams);

        await fdOld.close();
        await fdNew.close();

        const contributionHasher = blake2bWasm(64);
        hashPubKey(contributionHasher, curve, curContribution);

        const contribuionHash = contributionHasher.digest();

        if (logger) logger.info(formatHash(mpcParams.csHash, "Circuit Hash: "));
        if (logger) logger.info(formatHash(contribuionHash, "Contribution Hash: "));

        return contribuionHash;
    }

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */


    async function beacon(zkeyNameOld, zkeyNameNew, name, beaconHashStr, numIterationsExp, logger) {
        await blake2bWasm.ready();

        const beaconHash = hex2ByteArray(beaconHashStr);
        if (   (beaconHash.byteLength == 0)
            || (beaconHash.byteLength*2 !=beaconHashStr.length))
        {
            if (logger) logger.error("Invalid Beacon Hash. (It must be a valid hexadecimal sequence)");
            return false;
        }
        if (beaconHash.length>=256) {
            if (logger) logger.error("Maximum lenght of beacon hash is 255 bytes");
            return false;
        }

        numIterationsExp = parseInt(numIterationsExp);
        if ((numIterationsExp<10)||(numIterationsExp>63)) {
            if (logger) logger.error("Invalid numIterationsExp. (Must be between 10 and 63)");
            return false;
        }


        const maxZKeyVersion = 2;
        const zkey = await readHeader$1(zkeyNameOld, maxZKeyVersion);

        if (zkey.protocol != "groth16") {
            throw new Error("zkey file is not groth16");
        }


        const curve = await getCurveFromQ(zkey.q);

        const mpcParams = await readMPCParams(zkeyNameOld, maxZKeyVersion, curve);

        await createBinFile(zkeyNameNew, "zkey", 1, 10);

        const rng = await rngFromBeaconParams(beaconHash, numIterationsExp);

        const transcriptHasher = blake2bWasm(64);
        transcriptHasher.update(mpcParams.csHash);
        for (let i=0; i<mpcParams.contributions.length; i++) {
            hashPubKey(transcriptHasher, curve, mpcParams.contributions[i]);
        }

        const curContribution = {};
        curContribution.delta = {};
        curContribution.delta.prvKey = curve.Fr.fromRng(rng);
        curContribution.delta.g1_s = curve.G1.toAffine(curve.G1.fromRng(rng));
        curContribution.delta.g1_sx = curve.G1.toAffine(curve.G1.timesFr(curContribution.delta.g1_s, curContribution.delta.prvKey));
        hashG1(transcriptHasher, curve, curContribution.delta.g1_s);
        hashG1(transcriptHasher, curve, curContribution.delta.g1_sx);
        curContribution.transcript = transcriptHasher.digest();
        curContribution.delta.g2_sp = hashToG2(curve, curContribution.transcript);
        curContribution.delta.g2_spx = curve.G2.toAffine(curve.G2.timesFr(curContribution.delta.g2_sp, curContribution.delta.prvKey));

        zkey.vk_delta_1 = curve.G1.timesFr(zkey.vk_delta_1, curContribution.delta.prvKey);
        zkey.vk_delta_2 = curve.G2.timesFr(zkey.vk_delta_2, curContribution.delta.prvKey);

        curContribution.deltaAfter = zkey.vk_delta_1;

        curContribution.type = 1;
        curContribution.numIterationsExp = numIterationsExp;
        curContribution.beaconHash = beaconHash;

        if (name) curContribution.name = name;

        mpcParams.contributions.push(curContribution);

        await writeHeader(zkeyNameNew, zkey);

        // IC
        await copySectionFile(zkeyNameOld, zkeyNameNew, 3);

        // Coeffs (Keep original)
        await copySectionFile(zkeyNameOld, zkeyNameNew, 4);

        // A Section
        await copySectionFile(zkeyNameOld, zkeyNameNew, 5);

        // B1 Section
        await copySectionFile(zkeyNameOld, zkeyNameNew, 6);

        // B2 Section
        await copySectionFile(zkeyNameOld, zkeyNameNew, 7);

        const invDelta = curve.Fr.inv(curContribution.delta.prvKey);
        await applyKeyToSection(zkeyNameOld, maxZKeyVersion, zkeyNameNew, 8, curve, "G1", invDelta, curve.Fr.e(1), "L Section", logger);
        await applyKeyToSection(zkeyNameOld, maxZKeyVersion, zkeyNameNew, 9, curve, "G1", invDelta, curve.Fr.e(1), "H Section", logger);

        await writeMPCParams(zkeyNameNew, curve, mpcParams);

        const contributionHasher = blake2bWasm(64);
        hashPubKey(contributionHasher, curve, curContribution);

        const contribuionHash = contributionHasher.digest();

        if (logger) logger.info(formatHash(contribuionHash, "Contribution Hash: "));

        return contribuionHash;
    }

    async function zkeyExportJson(zkeyFileName) {

        const zKey = await readZKey(zkeyFileName, true);

        return zKey;
    }

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */

    async function bellmanContribute(curve, challengeFilename, responesFileName, entropy, logger) {
        await blake2bWasm.ready();

        const rng = await getRandomRng(entropy);

        const delta = curve.Fr.fromRng(rng);
        const invDelta = curve.Fr.inv(delta);

        const sG1 = curve.G1.F.n8*2;
        const sG2 = curve.G2.F.n8*2;

        const fdFrom = await readExisting(challengeFilename);
        const fdTo = await createOverride(responesFileName);


        await copy(sG1); // alpha1
        await copy(sG1); // beta1
        await copy(sG2); // beta2
        await copy(sG2); // gamma2
        const oldDelta1 = await readG1();
        const delta1 = curve.G1.timesFr(oldDelta1, delta);
        await writeG1(delta1);
        const oldDelta2 = await readG2();
        const delta2 = curve.G2.timesFr(oldDelta2, delta);
        await writeG2(delta2);

        // IC
        const nIC = await fdFrom.readUBE32();
        await fdTo.writeUBE32(nIC);
        await copy(nIC*sG1);

        // H
        const nH = await fdFrom.readUBE32();
        await fdTo.writeUBE32(nH);
        await applyKeyToChallengeSection(fdFrom, fdTo, null, curve, "G1", nH, invDelta, curve.Fr.e(1), "UNCOMPRESSED", "H", logger);

        // L
        const nL = await fdFrom.readUBE32();
        await fdTo.writeUBE32(nL);
        await applyKeyToChallengeSection(fdFrom, fdTo, null, curve, "G1", nL, invDelta, curve.Fr.e(1), "UNCOMPRESSED", "L", logger);

        // A
        const nA = await fdFrom.readUBE32();
        await fdTo.writeUBE32(nA);
        await copy(nA*sG1);

        // B1
        const nB1 = await fdFrom.readUBE32();
        await fdTo.writeUBE32(nB1);
        await copy(nB1*sG1);

        // B2
        const nB2 = await fdFrom.readUBE32();
        await fdTo.writeUBE32(nB2);
        await copy(nB2*sG2);


        //////////
        /// Read contributions
        //////////
        const transcriptHasher = blake2bWasm(64);

        const mpcParams = {};
        // csHash
        mpcParams.csHash =  await fdFrom.read(64);
        transcriptHasher.update(mpcParams.csHash);

        const nConttributions = await fdFrom.readUBE32();
        mpcParams.contributions = [];
        for (let i=0; i<nConttributions; i++) {
            const c = { delta:{} };
            c.deltaAfter = await readG1();
            c.delta.g1_s = await readG1();
            c.delta.g1_sx = await readG1();
            c.delta.g2_spx = await readG2();
            c.transcript = await fdFrom.read(64);
            mpcParams.contributions.push(c);
            hashPubKey(transcriptHasher, curve, c);
        }

        const curContribution = {};
        curContribution.delta = {};
        curContribution.delta.prvKey = delta;
        curContribution.delta.g1_s = curve.G1.toAffine(curve.G1.fromRng(rng));
        curContribution.delta.g1_sx = curve.G1.toAffine(curve.G1.timesFr(curContribution.delta.g1_s, delta));
        hashG1(transcriptHasher, curve, curContribution.delta.g1_s);
        hashG1(transcriptHasher, curve, curContribution.delta.g1_sx);
        curContribution.transcript = transcriptHasher.digest();
        curContribution.delta.g2_sp = hashToG2(curve, curContribution.transcript);
        curContribution.delta.g2_spx = curve.G2.toAffine(curve.G2.timesFr(curContribution.delta.g2_sp, delta));
        curContribution.deltaAfter = delta1;
        curContribution.type = 0;
        mpcParams.contributions.push(curContribution);


        //////////
        /// Write COntribution
        //////////

        await fdTo.write(mpcParams.csHash);
        await fdTo.writeUBE32(mpcParams.contributions.length);

        for (let i=0; i<mpcParams.contributions.length; i++) {
            const c = mpcParams.contributions[i];
            await writeG1(c.deltaAfter);
            await writeG1(c.delta.g1_s);
            await writeG1(c.delta.g1_sx);
            await writeG2(c.delta.g2_spx);
            await fdTo.write(c.transcript);
        }

        const contributionHasher = blake2bWasm(64);
        hashPubKey(contributionHasher, curve, curContribution);

        const contributionHash = contributionHasher.digest();

        if (logger) logger.info(formatHash(contributionHash, "Contribution Hash: "));

        await fdTo.close();
        await fdFrom.close();

        return contributionHash;

        async function copy(nBytes) {
            const CHUNK_SIZE = fdFrom.pageSize*2;
            for (let i=0; i<nBytes; i+= CHUNK_SIZE) {
                const n = Math.min(nBytes -i, CHUNK_SIZE);
                const buff = await fdFrom.read(n);
                await fdTo.write(buff);
            }
        }

        async function readG1() {
            const buff = await fdFrom.read(curve.G1.F.n8*2);
            return curve.G1.fromRprUncompressed(buff, 0);
        }

        async function readG2() {
            const buff = await fdFrom.read(curve.G2.F.n8*2);
            return curve.G2.fromRprUncompressed(buff, 0);
        }

        async function writeG1(P) {
            const buff = new Uint8Array(sG1);
            curve.G1.toRprUncompressed(buff, 0, P);
            await fdTo.write(buff);
        }

        async function writeG2(P) {
            const buff = new Uint8Array(sG2);
            curve.G2.toRprUncompressed(buff, 0, P);
            await fdTo.write(buff);
        }


    }

    /*
        Copyright 2018 0KIMS association.

        This file is part of snarkJS.

        snarkJS is a free software: you can redistribute it and/or modify it
        under the terms of the GNU General Public License as published by
        the Free Software Foundation, either version 3 of the License, or
        (at your option) any later version.

        snarkJS is distributed in the hope that it will be useful, but WITHOUT
        ANY WARRANTY; without even the implied warranty of MERCHANTABILITY
        or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public
        License for more details.

        You should have received a copy of the GNU General Public License
        along with snarkJS. If not, see <https://www.gnu.org/licenses/>.
    */
    const {stringifyBigInts: stringifyBigInts$1} = utils;

    async function zkeyExportVerificationKey(zkeyName, /* logger */ ) {
        const maxZKeyVersion = 2;

        const zkey = await readHeader$1(zkeyName, maxZKeyVersion);

        let res;
        if (zkey.protocol == "groth16") {
            res = await groth16Vk(zkey, zkeyName, maxZKeyVersion);
        } else if (zkey.protocol == "plonk") {
            res = await plonkVk(zkey);
        } else {
            throw new Error("zkey file is not groth16");
        }

        return res;
    }


    async function groth16Vk(zkey, zkeyFileName, maxZKeyVersion) {
        const curve = await getCurveFromQ(zkey.q);
        const sG1 = curve.G1.F.n8*2;

        const alphaBeta = await curve.pairing( zkey.vk_alpha_1 , zkey.vk_beta_2 );

        let vKey = {
            protocol: zkey.protocol,
            curve: curve.name,
            nPublic: zkey.nPublic,

            vk_alpha_1: curve.G1.toObject(zkey.vk_alpha_1),

            vk_beta_2: curve.G2.toObject(zkey.vk_beta_2),
            vk_gamma_2:  curve.G2.toObject(zkey.vk_gamma_2),
            vk_delta_2:  curve.G2.toObject(zkey.vk_delta_2),

            vk_alphabeta_12: curve.Gt.toObject(alphaBeta)
        };

        // Read IC Section
        ///////////
        const fd3 = await startReadSectionFile(zkeyFileName, 3, maxZKeyVersion);
        vKey.IC = [];
        for (let i=0; i<= zkey.nPublic; i++) {
            const buff = await fd3.read(sG1);
            const P = curve.G1.toObject(buff);
            vKey.IC.push(P);
        }
        await endReadSectionFile(fd3);

        vKey = stringifyBigInts$1(vKey);

        return vKey;
    }


    async function plonkVk(zkey) {
        const curve = await getCurveFromQ(zkey.q);

        let vKey = {
            protocol: zkey.protocol,
            curve: curve.name,
            nPublic: zkey.nPublic,
            power: zkey.power,

            k1: curve.Fr.toObject(zkey.k1),
            k2: curve.Fr.toObject(zkey.k2),

            Qm: curve.G1.toObject(zkey.Qm),
            Ql: curve.G1.toObject(zkey.Ql),
            Qr: curve.G1.toObject(zkey.Qr),
            Qo: curve.G1.toObject(zkey.Qo),
            Qc: curve.G1.toObject(zkey.Qc),
            S1: curve.G1.toObject(zkey.S1),
            S2: curve.G1.toObject(zkey.S2),
            S3: curve.G1.toObject(zkey.S3),

            X_2: curve.G2.toObject(zkey.X_2),

            w: curve.Fr.toObject(curve.Fr.w[zkey.power])
        };

        vKey = stringifyBigInts$1(vKey);

        return vKey;
    }

    var ejs = {};

    // Not ready yet
    // module.exports.generateVerifier_kimleeoh = generateVerifier_kimleeoh;
